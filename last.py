# pylint: disable=missing-class-docstring,missing-function-docstring,missing-module-docstring,unnecessary-lambda-assignment,unnecessary-lambda,line-too-long

from typing import Any
from dataclasses import dataclass

from llexer import ParseError, lexer

## AST boilerplate
def repr_list(v):
    return "[\n   " + "\n   ".join(i.pretty() if isinstance(i, Node) else repr_list(i) if isinstance(i, list) else repr(i) for i in v).replace("\n", "\n   ") + "\n]"

@dataclass
class Node:

    def pretty(self):
        args = "\n|--".join(f"{k}: {(v.pretty() if isinstance(v, Node) else repr_list(v) if isinstance(v, list) else repr(v)).replace('\n', '\n|  ')}" for k, v in self.__dict__.items() if k[0] != "_")
        return f"{self.__class__.__name__}\n|--{args}"

@dataclass
class Assign(Node):
    variables: list[Node]
    what: Node

@dataclass
class Call(Node):
    what: Node
    args: list[Node]

@dataclass
class Index(Node):
    what: Node
    idx: Node

@dataclass
class NameRef(Node):
    name: str

    def pretty(self):
        return f"NameRef {self.name}"

@dataclass
class Add(Node):
    lhs: Node
    rhs: Node

@dataclass
class Subtract(Node):
    lhs: Node
    rhs: Node

@dataclass
class Multiply(Node):
    lhs: Node
    rhs: Node

@dataclass
class Divide(Node):
    lhs: Node
    rhs: Node

@dataclass
class Parenthesized(Node):
    expr: Node

@dataclass
class Number(Node):
    data: str

    def pretty(self):
        return f"Number {self.data}"

@dataclass
class String(Node):
    data: str

    def pretty(self):
        return f"String {self.data!r}"

@dataclass
class Block(Node):
    stmts: list[Node]

## Parser boilerplate
@dataclass
class ParserState:
    """Monad representing the state of a parser"""

@dataclass
class OKParserState(ParserState):
    """ParserState subclass representing a state of an active parser"""
    tokens: list[tuple[tuple[str, int, int], tuple[str, str]]]
    results: Any

    def __rshift__(self, f):
        """Permutes the state with the given function"""
        return f(self.tokens, self.results)

@dataclass
class ErrorParserState(ParserState):
    """ParserState subclass representing a state of a parser that encountered an error"""
    pos: tuple[str, int, int]
    err: str

    def __rshift__(self, _f):
        """Permuting an error simply forwards it without change - errors break the pipeline"""
        return self

class _Pipeline:
    """Helper class for constructing parser pipelines
    (helps to cut down on the amount of `(lambda tok, rest: OKParserState(tok, rest) >> ...)` expressions)
    (and makes it harder to hit the recursion limit)"""

    def __init__(self, fs):
        self.fs = fs

    def __rshift__(self, f):
        if self.fs is None:
            return _Pipeline([f])
        return _Pipeline([*self.fs, f])

    def __call__(self, toks, results):
        state = OKParserState(toks, results)
        for f in self.fs:
            state >>= f
        return state

Pipeline = _Pipeline(None)

def ambig(*funcs):
    """Returns a parser that, from left to right, invokes every parser until it gets a non-error result.
If all parsers return errors, returns the error that's the furtherest right into the input."""
    def wrap(toks, prevs):
        result = None
        errors = []
        for func in funcs:
            result = OKParserState(toks, prevs) >> func
            if isinstance(result, OKParserState):
                return result
            errors.append(result)
        return max(errors, key=lambda x: x.pos[1:])
    return wrap

def next_token(expect=None):
    def wrap(toks, prevs):
        pos, tok = toks[0]
        if expect is None or tok[0] in expect:
            return OKParserState(toks[1:], [*prevs, tok])
        return ErrorParserState(pos, f"Expected one of {expect}")
    return wrap

### Start of parser code

## Helpers

# Constructs a parser that removes N prior results, and pushes a new result generated by `nodefunc`
set_result = lambda n, nodefunc: lambda toks, prevs: OKParserState(toks, [*(prevs[:-n] if n > 0 else prevs), nodefunc(prevs[-n:])])

# Constructs a parser that invokes the parser `func`, but ignores its changes to the results list
ignore = lambda func: Pipeline >> func >> set_result(2, lambda prevs: prevs[-2])

# Constructs a parser that consumes a token, but doesn't do anything with it and doesn't modify the results list
consume = lambda expect=None: Pipeline >> ignore(next_token(expect))

# Constructs a parser that checks if the next token matches a type without advancing the token stream
lookahead = lambda expect: lambda toks, results: OKParserState(toks, results) >> next_token(expect) >> (lambda *_: OKParserState(toks, results))

# Constructs a parser that consumes a token, invokes the `func` parser, and consumes another token
parse_surrounded = lambda func, left, right: Pipeline >> consume({left}) >> func >> consume({right})

# Returns a function that parses a comma-separated list of things parsed by `func`
parse_comma_list = lambda func: Pipeline >> func >> ambig(
    Pipeline >> next_token({"COMMA"}) >> (lambda *args: parse_comma_list(func)(*args)),
    Pipeline >> set_result(0, lambda _: [])
) >> set_result(2, lambda prevs: [prevs[0], *prevs[1]])

## Single token parsers

parse_name   = Pipeline >> next_token({"NAME"})   >> set_result(1, lambda prevs: NameRef(prevs[0][1]))
parse_string = Pipeline >> next_token({"QSTR"})   >> set_result(1, lambda prevs: String(prevs[0][1]))
parse_number = Pipeline >> next_token({"NUMBER"}) >> set_result(1, lambda prevs: Number(prevs[0][1]))

## Expression/subexpression parsers

parse_paren_expr_list = Pipeline >> parse_surrounded(parse_comma_list(lambda *args: parse_expr(*args)), "LPAREN", "RPAREN")
parse_call = ambig(
    Pipeline >> parse_name            >> parse_paren_expr_list >> set_result(2, lambda prevs: Call(*prevs)),
    Pipeline >> parse_name            >> parse_string          >> set_result(2, lambda prevs: Call(*prevs)),
    Pipeline >> parse_paren_expr_list >> parse_paren_expr_list >> set_result(2, lambda prevs: Call(*prevs)),
    Pipeline >> parse_paren_expr_list >> parse_string          >> set_result(2, lambda prevs: Call(*prevs))
)

def correct_right_recursion(types, cls, lhs, rhs):
    """Corrects the output of parse_expr; It's a right-recursive grammar, which incorrectly groups expressions
    like 1 + 2 - 3 into 1 + (2 - 3)"""
    if type(rhs) in types:
        return type(rhs)(correct_right_recursion(types, cls, lhs, rhs.lhs), rhs.rhs)
    return cls(lhs, rhs)

parse_paren_call_or_expr = Pipeline >> lookahead({"LPAREN"}) >> ambig(
    parse_call,
    Pipeline >> consume({"LPAREN"}) >> (lambda *args: parse_expr(*args)) >> consume({"RPAREN"}) >> set_result(1, lambda prevs: Parenthesized(prevs[0]))
)
parse_atom = ambig(parse_number, parse_string, parse_paren_call_or_expr, parse_call, parse_name)

# Operator precedence logic
parse_muldiv = lambda tok, res: OKParserState(tok, res) >> ambig(
    Pipeline >> parse_atom >> consume({"STAR"})  >> parse_muldiv >> set_result(2, lambda sides: correct_right_recursion((Multiply, Divide), Multiply, sides[0], sides[1])),
    Pipeline >> parse_atom >> consume({"SLASH"}) >> parse_muldiv >> set_result(2, lambda sides: correct_right_recursion((Multiply, Divide), Divide, sides[0], sides[1])),
    parse_atom
)
parse_addsub = lambda tok, res: OKParserState(tok, res) >> ambig(
    Pipeline >> parse_muldiv >> consume({"PLUS"}) >> parse_addsub >> set_result(2, lambda sides: correct_right_recursion((Add, Subtract), Add, sides[0], sides[1])),
    Pipeline >> parse_muldiv >> consume({"DASH"}) >> parse_addsub >> set_result(2, lambda sides: correct_right_recursion((Add, Subtract), Subtract, sides[0], sides[1])),
    parse_muldiv
)
parse_expr = parse_addsub  # The expression parser

## Top level construct parsers

# TODO: Support constructs like f()().x, x.y.z, etc.
parse_variable_suffix = Pipeline >> ambig(
    Pipeline >> consume({"DOT"}) >> parse_name                                            >> set_result(2, lambda prevs: Index(prevs[0], prevs[1])),
    Pipeline >> parse_surrounded(lambda *args: parse_expr(*args), "LBRACKET", "RBRACKET") >> set_result(2, lambda prevs: Index(prevs[0], prevs[1]))
)
parse_variable = ambig(
    Pipeline >> (lambda *args: parse_call(*args))                                       >> parse_variable_suffix,
    Pipeline >> parse_surrounded((lambda *args: parse_expr(*args)), "LPAREN", "RPAREN") >> parse_variable_suffix,
    Pipeline >> parse_name >> parse_variable_suffix,
    parse_name
)
parse_assignment = Pipeline >> parse_comma_list(parse_variable) >> consume({"EQUALS"}) >> (lambda *args: parse_expr(*args)) >> set_result(2, lambda prevs: Assign(prevs[0], prevs[1]))

parse_statement = Pipeline >> ambig(parse_assignment, parse_call)

parse_block = lambda end_toks: ambig(
    Pipeline >> parse_statement >> (lambda *args: parse_block(end_toks)(*args)) >> set_result(2, lambda prevs: Block([prevs[0], *prevs[1].stmts])),
    Pipeline >> ignore(next_token(end_toks)) >> set_result(0, lambda _: Block([]))
)

parse_chunk = parse_block({"EOF"})  # Parsing of a program starts here

## End of parser code

## This is the only function that should be used from this library
def parse(tokens):
    match OKParserState(tokens, []) >> parse_chunk:
        case OKParserState(_, [tree]):
            return tree
        case ErrorParserState(pos, err):
            raise ParseError(pos, err)
    raise RuntimeError("Parser somehow returned multiple results")

def main():
    program = """
-- Example program
x.y = print(1 - 2 - 3 / 4 / 5 - 6 - 7)
"""
    # Invoke lexer
    toks = list(lexer(program, "<string>"))
    toks.append((toks[-1][0], ("EOF", None)))

    # Invoke parser
    print(parse(toks).pretty())

if __name__ == "__main__":
    main()
